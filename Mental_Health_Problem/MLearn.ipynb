{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b77b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Downloads\\Program_project_py\\ML\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\user\\.cache\\kagglehub\\datasets\\xinwangcs\\stressor-cause-of-mental-health-problem-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"xinwangcs/stressor-cause-of-mental-health-problem-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e7b8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset: ['C:\\\\Users\\\\user\\\\.cache\\\\kagglehub\\\\datasets\\\\xinwangcs\\\\stressor-cause-of-mental-health-problem-dataset\\\\versions\\\\1\\\\stressor_test.json', 'C:\\\\Users\\\\user\\\\.cache\\\\kagglehub\\\\datasets\\\\xinwangcs\\\\stressor-cause-of-mental-health-problem-dataset\\\\versions\\\\1\\\\stressor_train.json']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "FILES = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".json\"):\n",
    "        PATH = os.path.join(path, file)\n",
    "        FILES.append(PATH )\n",
    "print(\"Files in dataset:\", FILES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b14378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stressor_class</th>\n",
       "      <th>stressor_word</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why are there always trivial matters in life t...</td>\n",
       "      <td>T1</td>\n",
       "      <td>financial</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After celebrating my 21st birthday, I truly fe...</td>\n",
       "      <td>T1</td>\n",
       "      <td>urged to marry</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the coming March, my work pressure will be ...</td>\n",
       "      <td>T1</td>\n",
       "      <td>work</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeed, the pressure of writing papers now is ...</td>\n",
       "      <td>T1</td>\n",
       "      <td>papers</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't learn it anymore, so let's just give u...</td>\n",
       "      <td>T1</td>\n",
       "      <td>can't learn it</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text stressor_class  \\\n",
       "0  Why are there always trivial matters in life t...             T1   \n",
       "1  After celebrating my 21st birthday, I truly fe...             T1   \n",
       "2  In the coming March, my work pressure will be ...             T1   \n",
       "3  Indeed, the pressure of writing papers now is ...             T1   \n",
       "4  I can't learn it anymore, so let's just give u...             T1   \n",
       "\n",
       "    stressor_word  interval  \n",
       "0       financial         8  \n",
       "1  urged to marry         8  \n",
       "2            work         8  \n",
       "3          papers         8  \n",
       "4  can't learn it         8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_data2dataframe(file):\n",
    "    \"\"\"\n",
    "    讀取 JSON 文件並將其轉換為 Pandas DataFrame。\n",
    "    參數:\n",
    "        file (str): 檔案路徑。\n",
    "\n",
    "    錯誤回報:\n",
    "        ValueError: 如果在資料集目錄中找不到 JSON 檔案。\n",
    "        ValueError: 如果指定的 JSON 檔案不存在。\n",
    "        \n",
    "    回傳:\n",
    "        pd.DataFrame: 包含文本、壓力源類別、壓力源詞和時間間隔的 DataFrame。\n",
    "    \"\"\"\n",
    "    if not FILES:\n",
    "        raise ValueError(\"No JSON files found in the dataset directory.\")\n",
    "    if not os.path.exists(file):\n",
    "        raise ValueError(f\"File '{file}' does not exist.\")\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(f\"Expected a list in JSON file, got {type(data)}\")\n",
    "        temp = []\n",
    "        for item in data:\n",
    "            #print(item)\n",
    "            TEXT = item[\"text\"]\n",
    "            INTERVAL = item[\"interval\"]\n",
    "            try:\n",
    "                STRESSOR_class = item[\"labels\"][0][0]\n",
    "                STRESSOR_WORD = item[\"labels\"][0][4]\n",
    "            except IndexError:\n",
    "                STRESSOR_class = np.nan\n",
    "                STRESSOR_WORD = np.nan\n",
    "            temp.append((TEXT, STRESSOR_class, STRESSOR_WORD, INTERVAL))\n",
    "\n",
    "    # Convert list of tuples to DataFrame with column names\n",
    "    return pd.DataFrame(temp, columns=[\"text\", \"stressor_class\", \"stressor_word\", \"interval\"])\n",
    "\n",
    "# Ensure each element is a DataFrame before concatenation\n",
    "dataframes = [load_data2dataframe(f) for f in FILES]\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45e5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7836fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              0\n",
       "stressor_class    0\n",
       "stressor_word     0\n",
       "interval          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c33ba08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stressor_class</th>\n",
       "      <th>stressor_word</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why are there always trivial matters in life t...</td>\n",
       "      <td>T1</td>\n",
       "      <td>financial</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After celebrating my 21st birthday, I truly fe...</td>\n",
       "      <td>T1</td>\n",
       "      <td>urged marry</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the coming March, my work pressure will be ...</td>\n",
       "      <td>T1</td>\n",
       "      <td>work</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeed, the pressure of writing papers now is ...</td>\n",
       "      <td>T1</td>\n",
       "      <td>papers</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't learn it anymore, so let's just give u...</td>\n",
       "      <td>T1</td>\n",
       "      <td>learn</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text stressor_class  \\\n",
       "0  Why are there always trivial matters in life t...             T1   \n",
       "1  After celebrating my 21st birthday, I truly fe...             T1   \n",
       "2  In the coming March, my work pressure will be ...             T1   \n",
       "3  Indeed, the pressure of writing papers now is ...             T1   \n",
       "4  I can't learn it anymore, so let's just give u...             T1   \n",
       "\n",
       "  stressor_word  interval  \n",
       "0     financial         8  \n",
       "1   urged marry         8  \n",
       "2          work         8  \n",
       "3        papers         8  \n",
       "4         learn         8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def normalize_word(word):\n",
    "    \"\"\"\n",
    "    詞彙正規化 :\n",
    "                小寫化\n",
    "                去除標點\n",
    "                去除多餘空白\n",
    "                去除停用詞\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)  # 移除標點符號\n",
    "    word = word.strip()\n",
    "    # 從 gensim 匯入停用詞\n",
    "    stopwords = STOPWORDS\n",
    "    words = [w for w in word.split() if w not in stopwords]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"stressor_word\"] = df[\"stressor_word\"].astype(str).apply(normalize_word)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53d6d8",
   "metadata": {},
   "source": [
    "Labels為分析對象，將其重新劃分分類至各主題，以去除類別數量懸殊問題\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc83192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "# 每筆 stressor_word 當作一篇文件（可分群）\n",
    "docs = df['stressor_word'].astype(str).str.split()  # 處理複數詞如 \"my mom\"\n",
    "dictionary = Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d9875dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主題 0: 0.243*\"the\" + 0.063*\"people\" + 0.060*\"me\" + 0.056*\"weight\" + 0.045*\"around\"\n",
      "主題 1: 0.201*\"a\" + 0.091*\"home\" + 0.052*\"house\" + 0.046*\"performance\" + 0.044*\"partner\"\n",
      "主題 2: 0.660*\"work\" + 0.072*\"to\" + 0.035*\"going\" + 0.028*\"go\" + 0.027*\"social\"\n",
      "主題 3: 0.165*\"school\" + 0.103*\"entrance\" + 0.082*\"graduate\" + 0.068*\"examination\" + 0.061*\"of\"\n",
      "主題 4: 0.108*\"high\" + 0.063*\"school\" + 0.032*\"year\" + 0.032*\"senior\" + 0.031*\"of\"\n",
      "主題 5: 0.068*\"year\" + 0.061*\"class\" + 0.059*\"project\" + 0.053*\"financial\" + 0.052*\"senior\"\n",
      "主題 6: 0.119*\"money\" + 0.073*\"paper\" + 0.051*\"graduation\" + 0.049*\"brother\" + 0.047*\"public\"\n",
      "主題 7: 0.336*\"exam\" + 0.061*\"panic\" + 0.048*\"exams\" + 0.047*\"big\" + 0.022*\"tasks\"\n",
      "主題 8: 0.202*\"my\" + 0.123*\"mom\" + 0.115*\"parents\" + 0.054*\"dad\" + 0.038*\"in\"\n",
      "主題 9: 0.112*\"being\" + 0.099*\"academic\" + 0.042*\"peers\" + 0.039*\"is\" + 0.037*\"love\"\n",
      "主題 10: 0.622*\"life\" + 0.037*\"peer\" + 0.027*\"thesis\" + 0.021*\"online\" + 0.019*\"retest\"\n",
      "主題 11: 0.095*\"working\" + 0.090*\"study\" + 0.055*\"overtime\" + 0.052*\"driving\" + 0.044*\"at\"\n",
      "主題 12: 0.202*\"family\" + 0.093*\"economic\" + 0.054*\"for\" + 0.039*\"meeting\" + 0.037*\"report\"\n",
      "主題 13: 0.048*\"interview\" + 0.046*\"friends\" + 0.032*\"little\" + 0.030*\"taking\" + 0.029*\"leader\"\n",
      "主題 14: 0.069*\"everyone\" + 0.055*\"sister\" + 0.054*\"marriage\" + 0.051*\"employment\" + 0.040*\"pressure\"\n",
      "主題 15: 0.113*\"myself\" + 0.063*\"research\" + 0.058*\"survival\" + 0.046*\"training\" + 0.040*\"group\"\n",
      "主題 16: 0.321*\"job\" + 0.034*\"getting\" + 0.027*\"married\" + 0.025*\"cat\" + 0.025*\"living\"\n",
      "主題 17: 0.163*\"studying\" + 0.119*\"new\" + 0.064*\"get\" + 0.057*\"married\" + 0.048*\"to\"\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel(corpus=corpus,\n",
    "                   id2word=dictionary, \n",
    "                   num_topics=18, random_state=42, passes=10)\n",
    "topics = lda.print_topics(num_words=5)\n",
    "for i, topic in topics:\n",
    "    print(f\"主題 {i}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主題數量: 18\n",
      "主題 ID 列表: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "\n",
      "主題 0: 0.243*\"the\" + 0.063*\"people\" + 0.060*\"me\" + 0.056*\"weight\" + 0.045*\"around\"\n",
      "主題 1: 0.201*\"a\" + 0.091*\"home\" + 0.052*\"house\" + 0.046*\"performance\" + 0.044*\"partner\"\n",
      "主題 2: 0.660*\"work\" + 0.072*\"to\" + 0.035*\"going\" + 0.028*\"go\" + 0.027*\"social\"\n",
      "主題 3: 0.165*\"school\" + 0.103*\"entrance\" + 0.082*\"graduate\" + 0.068*\"examination\" + 0.061*\"of\"\n",
      "主題 4: 0.108*\"high\" + 0.063*\"school\" + 0.032*\"year\" + 0.032*\"senior\" + 0.031*\"of\"\n",
      "主題 5: 0.068*\"year\" + 0.061*\"class\" + 0.059*\"project\" + 0.053*\"financial\" + 0.052*\"senior\"\n",
      "主題 6: 0.119*\"money\" + 0.073*\"paper\" + 0.051*\"graduation\" + 0.049*\"brother\" + 0.047*\"public\"\n",
      "主題 7: 0.336*\"exam\" + 0.061*\"panic\" + 0.048*\"exams\" + 0.047*\"big\" + 0.022*\"tasks\"\n",
      "主題 8: 0.202*\"my\" + 0.123*\"mom\" + 0.115*\"parents\" + 0.054*\"dad\" + 0.038*\"in\"\n",
      "主題 9: 0.112*\"being\" + 0.099*\"academic\" + 0.042*\"peers\" + 0.039*\"is\" + 0.037*\"love\"\n",
      "主題 10: 0.622*\"life\" + 0.037*\"peer\" + 0.027*\"thesis\" + 0.021*\"online\" + 0.019*\"retest\"\n",
      "主題 11: 0.095*\"working\" + 0.090*\"study\" + 0.055*\"overtime\" + 0.052*\"driving\" + 0.044*\"at\"\n",
      "主題 12: 0.202*\"family\" + 0.093*\"economic\" + 0.054*\"for\" + 0.039*\"meeting\" + 0.037*\"report\"\n",
      "主題 13: 0.048*\"interview\" + 0.046*\"friends\" + 0.032*\"little\" + 0.030*\"taking\" + 0.029*\"leader\"\n",
      "主題 14: 0.069*\"everyone\" + 0.055*\"sister\" + 0.054*\"marriage\" + 0.051*\"employment\" + 0.040*\"pressure\"\n",
      "主題 15: 0.113*\"myself\" + 0.063*\"research\" + 0.058*\"survival\" + 0.046*\"training\" + 0.040*\"group\"\n",
      "主題 16: 0.321*\"job\" + 0.034*\"getting\" + 0.027*\"married\" + 0.025*\"cat\" + 0.025*\"living\"\n",
      "主題 17: 0.163*\"studying\" + 0.119*\"new\" + 0.064*\"get\" + 0.057*\"married\" + 0.048*\"to\"\n"
     ]
    }
   ],
   "source": [
    "# 將每筆文字轉成 BOW 格式\n",
    "def get_topic_id(stressor_word: str , lda=lda, dictionary=dictionary):\n",
    "    \"\"\"取得每筆 stressor_word 的主題 ID\"\"\"\n",
    "    text_split = stressor_word.split()  # 假設 stressor_word 是一個詞組\n",
    "    bow = dictionary.doc2bow(text_split)\n",
    "    if not bow:\n",
    "        return None\n",
    "    topic_probs = lda.get_document_topics(bow)\n",
    "    topic_probs = sorted(topic_probs, key=lambda x: x[1], reverse=True)\n",
    "    return topic_probs[0][0]  # 取機率最高的主題 ID\n",
    "\n",
    "# 加入 topic_id 欄\n",
    "df[\"topic_id\"] = df[\"stressor_word\"].astype(str).apply(get_topic_id , lda=lda, dictionary=dictionary)\n",
    "# theme = df[\"topic_id\"].unique()\n",
    "# theme = sorted(theme)\n",
    "# print(\"主題數量:\", len(theme))\n",
    "# print(\"主題 ID 列表:\", theme)\n",
    "# print()\n",
    "# # 顯示每個主題的詞彙\n",
    "# for topic_id in theme:\n",
    "#     keywords = lda.print_topic(topic_id,topn=5)\n",
    "#     print(f\"主題 {topic_id}: {keywords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c853219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主題 0: 次數=386，關鍵詞=0.243*\"the\" + 0.063*\"people\" + 0.060*\"me\"\n",
      "主題 1: 次數=180，關鍵詞=0.201*\"a\" + 0.091*\"home\" + 0.052*\"house\"\n",
      "主題 2: 次數=633，關鍵詞=0.660*\"work\" + 0.072*\"to\" + 0.035*\"going\"\n",
      "主題 3: 次數=253，關鍵詞=0.165*\"school\" + 0.103*\"entrance\" + 0.082*\"graduate\"\n",
      "主題 4: 次數=105，關鍵詞=0.108*\"high\" + 0.063*\"school\" + 0.032*\"year\"\n",
      "主題 5: 次數=152，關鍵詞=0.068*\"year\" + 0.061*\"class\" + 0.059*\"project\"\n",
      "主題 6: 次數=175，關鍵詞=0.119*\"money\" + 0.073*\"paper\" + 0.051*\"graduation\"\n",
      "主題 7: 次數=189，關鍵詞=0.336*\"exam\" + 0.061*\"panic\" + 0.048*\"exams\"\n",
      "主題 8: 次數=245，關鍵詞=0.202*\"my\" + 0.123*\"mom\" + 0.115*\"parents\"\n",
      "主題 9: 次數=134，關鍵詞=0.112*\"being\" + 0.099*\"academic\" + 0.042*\"peers\"\n",
      "主題 10: 次數=389，關鍵詞=0.622*\"life\" + 0.037*\"peer\" + 0.027*\"thesis\"\n",
      "主題 11: 次數=216，關鍵詞=0.095*\"working\" + 0.090*\"study\" + 0.055*\"overtime\"\n",
      "主題 12: 次數=152，關鍵詞=0.202*\"family\" + 0.093*\"economic\" + 0.054*\"for\"\n",
      "主題 13: 次數=146，關鍵詞=0.048*\"interview\" + 0.046*\"friends\" + 0.032*\"little\"\n",
      "主題 14: 次數=145，關鍵詞=0.069*\"everyone\" + 0.055*\"sister\" + 0.054*\"marriage\"\n",
      "主題 15: 次數=152，關鍵詞=0.113*\"myself\" + 0.063*\"research\" + 0.058*\"survival\"\n",
      "主題 16: 次數=151，關鍵詞=0.321*\"job\" + 0.034*\"getting\" + 0.027*\"married\"\n",
      "主題 17: 次數=182，關鍵詞=0.163*\"studying\" + 0.119*\"new\" + 0.064*\"get\"\n",
      "總計 3985 筆資料\n"
     ]
    }
   ],
   "source": [
    "# 統計每個主題出現次數\n",
    "topic_counts = df[\"topic_id\"].value_counts().sort_index()\n",
    "counts = 0\n",
    "for tid, count in topic_counts.items():\n",
    "    #print(tid, count)\n",
    "    keywords = lda.print_topic(int(tid), topn=3)\n",
    "    print(f\"主題 {tid}: 次數={count}，關鍵詞={keywords}\")\n",
    "    counts += count\n",
    "print(f\"總計 {counts} 筆資料\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8c10da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.54      0.37        74\n",
      "           1       0.45      0.38      0.41        45\n",
      "           2       0.77      0.70      0.73       116\n",
      "           3       0.54      0.56      0.55        50\n",
      "           4       0.19      0.25      0.22        20\n",
      "           5       0.52      0.39      0.45        33\n",
      "           6       0.54      0.38      0.44        40\n",
      "           7       0.50      0.50      0.50        28\n",
      "           8       0.46      0.47      0.46        49\n",
      "           9       0.57      0.46      0.51        28\n",
      "          10       0.72      0.70      0.71        71\n",
      "          11       0.46      0.42      0.44        43\n",
      "          12       0.57      0.40      0.47        40\n",
      "          13       0.39      0.39      0.39        28\n",
      "          14       0.29      0.20      0.24        30\n",
      "          15       0.53      0.49      0.51        35\n",
      "          16       0.52      0.50      0.51        30\n",
      "          17       0.65      0.54      0.59        37\n",
      "\n",
      "    accuracy                           0.50       797\n",
      "   macro avg       0.50      0.46      0.47       797\n",
      "weighted avg       0.53      0.50      0.51       797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"topic_id\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = SVC(kernel='linear', random_state=42 , class_weight='balanced')\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2058e703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.50783699 0.5015674  0.51097179 0.53291536 0.50470219 0.50783699\n",
      " 0.51097179 0.51097179 0.50943396 0.55031447]\n",
      "Average cross-validation score: 0.5147522722343802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X_train_vec, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average cross-validation score:\", scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
